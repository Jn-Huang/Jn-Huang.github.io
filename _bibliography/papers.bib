---
---
% importabt to add this: selected={true}, 
@article{li2024scilitllm,
  title={SciLitLLM: How to Adapt LLMs for Scientific Literature Understanding},
  author={Li*, Sihang and Huang*, Jin and Zhuang, Jiaxi and Shi, Yaorui and Cai, Xiaochen and Xu, Mingjun and Wang, Xiang and Zhang, Linfeng and Ke, Guolin and Cai, Hengxing},
  journal={Foundation Models for Science Workshop, NeurIPS},
  selected={true}, 
  year={2024},
  html={http://www.arxiv.org/abs/2408.15545},
  blog={https://scilitllms.github.io},
  code={https://github.com/dptech-corp/Uni-SMART/tree/main/SciLitLLM},
}

@article{cai2024sciassess,
  title={Sciassess: Benchmarking llm proficiency in scientific literature analysis},
  author={Cai, Hengxing and Cai, Xiaochen and Chang, Junhan and Li, Sihang and Yao, Lin and Wang, Changxin and Gao, Zhifeng and Li, Yongge and Lin, Mujie and Yang, Shuwen and others},
  journal={arXiv preprint arXiv:2403.01976},
  year={2024},
  html={https://arxiv.org/abs/2403.01976},
}

@misc{zhang2024massw,
      title={MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows}, 
      author={Xingjian Zhang and Yutong Xie and Jin Huang and Jinge Ma and Zhaoying Pan and Qijia Liu and Ziyang Xiong and Tolga Ergen and Dongsub Shim and Honglak Lee and Qiaozhu Mei},
      year={2024},
      eprint={2406.06357},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      abbr={arxiv},
      html={https://arxiv.org/abs/2406.06357},
      code={https://github.com/xingjian-zhang/massw}
}

@misc{huang2024dcabench,
      title={DCA-Bench: A Benchmark for Dataset Curation Agents}, 
      author={Benhao Huang and Yingzhuo Yu and Jin Huang and Xingjian Zhang and Jiaqi Ma},
      year={2024},
      eprint={2406.07275},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      abbr={arxiv},
      html={https://arxiv.org/abs/2406.07275},
      code={https://github.com/TRAIS-Lab/dca-bench}
}

@article{huang2024can,
      title={Can {LLM}s Effectively Leverage Graph Structural Information through Prompts, and Why?},
      author={Jin Huang and Xingjian Zhang and Qiaozhu Mei and Jiaqi Ma},
      journal={Transactions on Machine Learning Research},
      issn={2835-8856},
      selected={true}, 
      year={2024},
      url={https://openreview.net/forum?id=L2jRavXRxs},
      html={https://arxiv.org/abs/2309.16595},
      abbr={TMLR},
      code={https://github.com/TRAIS-Lab/LLM-Structured-Data},
}


@InProceedings{pmlr-v198-ma22a,
  title = 	 {Graph Learning Indexer: A Contributor-Friendly and Metadata-Rich Platform for Graph Learning Benchmarks},
  author =       {Ma, Jiaqi and Zhang, Xingjian and Fan, Hezheng and Huang, Jin and Li, Tianyue and Li, Ting Wei and Tu, Yiwen and Zhu, Chenshu and Mei, Qiaozhu},
  booktitle = 	 {Proceedings of the First Learning on Graphs Conference},
  pages = 	 {7:1--7:23},
  year = 	 {2022},
  editor = 	 {Rieck, Bastian and Pascanu, Razvan},
  volume = 	 {198},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--12 Dec},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v198/ma22a/ma22a.pdf},
  url = 	 {https://proceedings.mlr.press/v198/ma22a.html},
  abbr = {LoG 2022},
  abstract = 	 {Establishing open and general benchmarks has been a critical driving force behind the success of modern machine learning techniques. As machine learning is being applied to broader domains and tasks, there is a need to establish richer and more diverse benchmarks to better reflect the reality of the application scenarios. Graph learning is an emerging field of machine learning that urgently needs more and better benchmarks. To accommodate the need, we introduce Graph Learning Indexer (GLI), a benchmark curation platform for graph learning. In comparison to existing graph learning benchmark libraries, GLI highlights two novel design objectives. First, GLI is designed to incentivize \emph{dataset contributors}. In particular, we incorporate various measures to minimize the effort of contributing and maintaining a dataset, increase the usability of the contributed dataset, as well as encourage attributions to different contributors of the dataset. Second, GLI is designed to curate a knowledge base, instead of a plain collection, of benchmark datasets. We use multiple sources of meta information to augment the benchmark datasets with \emph{rich characteristics}, so that they can be easily selected and used in downstream research or development. The source code of GLI is available at \url{https://github.com/Graph-Learning-Benchmarks/gli}. }
}


