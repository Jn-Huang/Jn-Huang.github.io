---
---
% importabt to add this: selected={true}, 
@article{li2024scilitllm,
  title={SciLitLLM: How to Adapt LLMs for Scientific Literature Understanding},
  author={Li*, Sihang and Huang*, Jin and Zhuang, Jiaxi and Shi, Yaorui and Cai, Xiaochen and Xu, Mingjun and Wang, Xiang and Zhang, Linfeng and Ke, Guolin and Cai, Hengxing},
  journal={International Conference on Learning Representations},
  selected={true}, 
  year={2025},
  abbr={ICLR 2025},
  html={http://www.arxiv.org/abs/2408.15545},
  blog={https://scilitllms.github.io},
  code={https://github.com/dptech-corp/Uni-SMART/tree/main/SciLitLLM},
}

@article{cai2024sciassess,
  title={Sciassess: Benchmarking llm proficiency in scientific literature analysis},
  author={Cai, Hengxing and Cai, Xiaochen and Chang, Junhan and Li, Sihang and Yao, Lin and Wang, Changxin and Gao, Zhifeng and Li, Yongge and Lin, Mujie and Yang, Shuwen and others},
  journal={The Nations of the Americas Chapter of the Association for Computational Linguistics},
  abbr={NAACL 2025},
  year={2025},
  html={https://arxiv.org/abs/2403.01976},
}

@misc{zhang2024massw,
      title={MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows}, 
      author={Xingjian Zhang and Yutong Xie and Jin Huang and Jinge Ma and Zhaoying Pan and Qijia Liu and Ziyang Xiong and Tolga Ergen and Dongsub Shim and Honglak Lee and Qiaozhu Mei},
      year={2025},
      journal={The Nations of the Americas Chapter of the Association for Computational Linguistics},
      abbr={NAACL 2025},
      html={https://arxiv.org/abs/2406.06357},
      code={https://github.com/xingjian-zhang/massw}
}

@misc{huang2024dcabench,
      title={DCA-Bench: A Benchmark for Dataset Curation Agents}, 
      author={Benhao Huang and Yingzhuo Yu and Jin Huang and Xingjian Zhang and Jiaqi Ma},
      year={2024},
      eprint={2406.07275},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      abbr={arxiv},
      html={https://arxiv.org/abs/2406.07275},
      code={https://github.com/TRAIS-Lab/dca-bench}
}

@article{huang2024can,
      title={Can {LLM}s Effectively Leverage Graph Structural Information through Prompts, and Why?},
      author={Jin Huang and Xingjian Zhang and Qiaozhu Mei and Jiaqi Ma},
      journal={Transactions on Machine Learning Research},
      issn={2835-8856},
      selected={true}, 
      year={2024},
      url={https://openreview.net/forum?id=L2jRavXRxs},
      html={https://arxiv.org/abs/2309.16595},
      abbr={TMLR 2024},
      code={https://github.com/TRAIS-Lab/LLM-Structured-Data},
}


@InProceedings{pmlr-v198-ma22a,
  title = 	 {Graph Learning Indexer: A Contributor-Friendly and Metadata-Rich Platform for Graph Learning Benchmarks},
  author =       {Ma, Jiaqi and Zhang, Xingjian and Fan, Hezheng and Huang, Jin and Li, Tianyue and Li, Ting Wei and Tu, Yiwen and Zhu, Chenshu and Mei, Qiaozhu},
  booktitle = 	 {Proceedings of the First Learning on Graphs Conference},
  pages = 	 {7:1--7:23},
  year = 	 {2022},
  editor = 	 {Rieck, Bastian and Pascanu, Razvan},
  volume = 	 {198},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--12 Dec},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v198/ma22a/ma22a.pdf},
  url = 	 {https://proceedings.mlr.press/v198/ma22a.html},
  abbr = {LoG 2022},
  abstract = 	 {Establishing open and general benchmarks has been a critical driving force behind the success of modern machine learning techniques. As machine learning is being applied to broader domains and tasks, there is a need to establish richer and more diverse benchmarks to better reflect the reality of the application scenarios. Graph learning is an emerging field of machine learning that urgently needs more and better benchmarks. To accommodate the need, we introduce Graph Learning Indexer (GLI), a benchmark curation platform for graph learning. In comparison to existing graph learning benchmark libraries, GLI highlights two novel design objectives. First, GLI is designed to incentivize \emph{dataset contributors}. In particular, we incorporate various measures to minimize the effort of contributing and maintaining a dataset, increase the usability of the contributed dataset, as well as encourage attributions to different contributors of the dataset. Second, GLI is designed to curate a knowledge base, instead of a plain collection, of benchmark datasets. We use multiple sources of meta information to augment the benchmark datasets with \emph{rich characteristics}, so that they can be easily selected and used in downstream research or development. The source code of GLI is available at \url{https://github.com/Graph-Learning-Benchmarks/gli}. }
}

@InProceedings{pmlr-v202-chen23s,
  title = 	 {{H}arsanyi{N}et: Computing Accurate Shapley Values in a Single Forward Propagation},
  author =       {Chen, Lu and Lou, Siyu and Zhang, Keyan and Huang, Jin and Zhang, Quanshi},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2023},
  pdf = 	 {https://proceedings.mlr.press/v202/chen23s/chen23s.pdf},
  url = 	 {https://proceedings.mlr.press/v202/chen23s.html},
  abbr = {ICML 2023},
  abstract = 	 {The Shapley value is widely regarded as a trustworthy attribution metric. However, when people use Shapley values to explain the attribution of input variables of a deep neural network (DNN), it usually requires a very high computational cost to approximate relatively accurate Shapley values in real-world applications. Therefore, we propose a novel network architecture, the HarsanyiNet, which makes inferences on the input sample and simultaneously computes the exact Shapley values of the input variables in a single forward propagation. The HarsanyiNet is designed on the theoretical foundation that the Shapley value can be reformulated as the redistribution of Harsanyi interactions encoded by the network.}
}
